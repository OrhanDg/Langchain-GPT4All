{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m8V_tUtqJ1o"
      },
      "source": [
        "# Ein Custom LLM Model mit Langchain und GPT4All"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/drive/MyDrive/Forschungstudie_Beckmann/model.gguf \"https://gpt4all.io/models/gguf/wizardlm-13b-v1.2.Q4_0.gguf\".   # /content/drive/MyDrive/Forschungstudie_Beckmann/model.gguf(Eigener Pfad eingeben)"
      ],
      "metadata": {
        "id": "XU2Sslw6UCz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5W6FgwUqLhH"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import GPT4All\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km_0wGHZqV0G"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F_BD_SGqSEU"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Forschungstudie_Beckmann/Hochschule_Heilbronn_Wikipedia.pdf\")\n",
        "documents = loader.load_and_split()\n",
        "# print(documents[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQeMcNHq8EoQ"
      },
      "source": [
        "## Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCasR6An8Fwj"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "print(texts[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0tJVA0S8NCN"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzqlxQj_8OT0"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"deutsche-telekom/gbert-large-paraphrase-cosine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8S4lQp6a8ROf"
      },
      "outputs": [],
      "source": [
        "db = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv8qYJDr8Uur"
      },
      "source": [
        "## Creating Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SO-iC-88XNT"
      },
      "outputs": [],
      "source": [
        "model_n_ctx = 1000\n",
        "model_path = \"/content/drive/MyDrive/Forschungstudie_Beckmann/model.gguf\"\n",
        "callbacks = [StreamingStdOutCallbackHandler()]\n",
        "llm= GPT4All(model=model_path, callbacks=callbacks, verbose=True,n_threads=16, temp=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkHAKVIT8blw"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True,\n",
        "    verbose=False,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUVWWycB8eMz"
      },
      "source": [
        "## Ask Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7dbNbFm8gYn",
        "outputId": "9ee1cb36-1801-4a56-b1c1-48c23103b296"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Die Gr端ndung von HHN (Heilbronner Institut f端r Lebenslanges Lernen) erfolgte am 17. April 1961, als die Vorlaufschule \"Staatliche Ingenieurschule Heilbronn\" gegr端ndet wurde.CPU times: user 6h 42min 38s, sys: 39min 58s, total: 7h 22min 37s\n",
            "Wall time: 6h 13min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "res = qa(\n",
        "    \"Wann ist HHN gegr端ndet?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkhpF-mD8mKE"
      },
      "outputs": [],
      "source": [
        "print(res[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6p2x9dP8pC6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "prompt = f\"\"\"How much is the investment amount in Microsoft on 6/22? Extract the answer from the text.\"\"\"\n",
        "res = qa(prompt.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otVyITOB8qcn"
      },
      "outputs": [],
      "source": [
        "print(res[\"result\"])"
      ]
    }
  ]
}